{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neurohack2022.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Start**"
      ],
      "metadata": {
        "id": "7Aw817bhfEK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "#import numpy for linear algebra operations\n",
        "import numpy as np\n",
        "#import matplotlib for data visualization and graphical plotting\n",
        "from matplotlib import pyplot as plt\n",
        "#import seaborn for data visualization for statistical graphics plotting\n",
        "import seaborn as sns\n",
        "#import pickle for serializing and de-serializing python object structures\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "#for data split : training and testing (here, validation)\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "#for statitics of results obtained\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "#importing various ML methods to train data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "xLHGn8ut-ejz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "column_data = pd.read_csv(io.BytesIO(uploaded['Metadata_LASI-DAD.csv']))\n",
        "#column_data\n",
        "col_name = np.array(column_data['variable'])\n",
        "#col_name"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "H5f791qno_te",
        "outputId": "7ca0e000-b1ee-4fd9-a833-57d8cacac88b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6b106b85-d916-4d65-a428-df44414b0f7b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6b106b85-d916-4d65-a428-df44414b0f7b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Metadata_LASI-DAD.csv to Metadata_LASI-DAD.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "gFsyglaV-cdI",
        "outputId": "7389dcbd-ecca-4fb8-df96-6a1a94d3f6f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1d071d87-5cf8-414f-a95f-3d605cd841d8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1d071d87-5cf8-414f-a95f-3d605cd841d8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving H_DAD_w1a3.csv to H_DAD_w1a3.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "full_data = pd.read_csv(io.BytesIO(uploaded['H_DAD_w1a3.csv']))\n",
        "#full_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "train_data = pd.read_csv(io.BytesIO(uploaded['processed_filled.csv']))\n",
        "#train_data"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "gN8XOPNBU29n",
        "outputId": "a471455a-b6fa-4e94-95f9-c4e315c23679"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7e4e8261-3779-438f-882c-44185dd5022d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7e4e8261-3779-438f-882c-44185dd5022d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving processed_filled.csv to processed_filled.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def printinfo(data):\n",
        "    temp = pd.DataFrame(index = data.columns)\n",
        "    temp['data_type'] = data.dtypes\n",
        "    temp['null_count'] = data.isnull().sum()\n",
        "    display(temp)"
      ],
      "metadata": {
        "id": "togRoYrd-esM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ],
      "metadata": {
        "id": "fsW6QgyVfMl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(train_data, full_data, col_name):\n",
        "  train_data['r1agey'] = full_data['r1agey']\n",
        "  train_data['r1prs_topkun'] = full_data['r1prs_topkun']\n",
        "  train_data['r1prs_pc4'] = full_data['r1prs_pc4']\n",
        "  train_data['r1cdr_incon'] = full_data['r1cdr_incon']\n",
        "  train_data['r1prs_pc5'] = full_data['r1prs_pc5']\n",
        "  train_data['r1obshouse'] = full_data['r1obshouse']\n",
        "  train_data['r1rs7412'] = full_data['r1rs7412']\n",
        "  train_data['r1obsnoise'] = full_data['r1obsnoise']\n",
        "  train_data['r1prs_topcog'] = full_data['r1prs_topcog']\n",
        "  train_data['r1cdr_final'] = full_data['r1cdr_final']\n",
        "  train_data['r1obsodor'] = full_data['r1obsodor']\n",
        "  train_data['r1obsair'] = full_data['r1obsair']\n",
        "  train_data['r1prs_pc3'] = full_data['r1prs_pc3']\n",
        "  train_data['r1rs429358'] = full_data['r1rs429358']\n",
        "  train_data['r1prs_pc1'] = full_data['r1prs_pc1']\n",
        "  train_data['r1spice'] = full_data['r1spice']\n",
        "  train_data['raedyrs'] = full_data['raedyrs']\n",
        "  train_data['r1prs_topjan'] = full_data['r1prs_topjan']\n",
        "  train_data['r1prs_pc2'] = full_data['r1prs_pc2']\n",
        "  train_data['r1location'] = full_data['r1location']\n",
        "  train_data['r1prs_toplam'] = full_data['r1prs_toplam']\n",
        "  train_data['ragender'] = full_data['ragender']\n",
        "  training_data = train_data[col_name]\n",
        "  training_data = training_data.fillna(-1)\n",
        "  del training_data['r1cdr_incon']\n",
        "  return training_data"
      ],
      "metadata": {
        "id": "hA10wcqNrb4e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = preprocess(train_data, full_data, col_name)\n",
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "OPtjKN1ozAAB",
        "outputId": "de85909e-987d-46fe-aa67-adb7bc381f5b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4b1971c7-d6a8-4e87-be6e-0e157daca7d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prim_key</th>\n",
              "      <th>r1agey</th>\n",
              "      <th>ragender</th>\n",
              "      <th>raedyrs</th>\n",
              "      <th>h1rural</th>\n",
              "      <th>r1location</th>\n",
              "      <th>r1wtresp</th>\n",
              "      <th>r1obsnoise</th>\n",
              "      <th>r1obsodor</th>\n",
              "      <th>r1obsair</th>\n",
              "      <th>r1obshouse</th>\n",
              "      <th>r1borient</th>\n",
              "      <th>r1bexefu</th>\n",
              "      <th>r1blangf</th>\n",
              "      <th>r1bmemory</th>\n",
              "      <th>r1bvsp</th>\n",
              "      <th>r1nmemimm</th>\n",
              "      <th>r1nmemdel</th>\n",
              "      <th>r1nmemrec</th>\n",
              "      <th>r1nreason</th>\n",
              "      <th>r1natnspd</th>\n",
              "      <th>r1sgcp</th>\n",
              "      <th>r1hmse_scorz</th>\n",
              "      <th>r1word_totaz</th>\n",
              "      <th>r1word_dz</th>\n",
              "      <th>r1wre_scorez</th>\n",
              "      <th>r1log_recoz</th>\n",
              "      <th>r1bm_immexz</th>\n",
              "      <th>r1bm_reclexz</th>\n",
              "      <th>r1verbalz</th>\n",
              "      <th>r1csid_scorz</th>\n",
              "      <th>r1rv_scorez</th>\n",
              "      <th>r1cog_totalz</th>\n",
              "      <th>r1i_hear</th>\n",
              "      <th>r1i_sleep</th>\n",
              "      <th>r1systo</th>\n",
              "      <th>r1diasto</th>\n",
              "      <th>r1pulse</th>\n",
              "      <th>r1bphigh</th>\n",
              "      <th>r1mheight</th>\n",
              "      <th>r1mweight</th>\n",
              "      <th>r1mbmi</th>\n",
              "      <th>r1bmicat</th>\n",
              "      <th>r1adla_d</th>\n",
              "      <th>r1iadltot1_d</th>\n",
              "      <th>r1cesd10</th>\n",
              "      <th>r1anx5</th>\n",
              "      <th>r1mna_scale</th>\n",
              "      <th>r1spice</th>\n",
              "      <th>r1hear_r</th>\n",
              "      <th>r1hear_l</th>\n",
              "      <th>r1hear_aid</th>\n",
              "      <th>r1prs_toplam</th>\n",
              "      <th>r1prs_topkun</th>\n",
              "      <th>r1prs_topjan</th>\n",
              "      <th>r1prs_topcog</th>\n",
              "      <th>r1prs_pc1</th>\n",
              "      <th>r1prs_pc2</th>\n",
              "      <th>r1prs_pc3</th>\n",
              "      <th>r1prs_pc4</th>\n",
              "      <th>r1prs_pc5</th>\n",
              "      <th>r1rs7412</th>\n",
              "      <th>r1rs429358</th>\n",
              "      <th>r1cdr_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.010000e+14</td>\n",
              "      <td>68</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.484271</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>-1.010781</td>\n",
              "      <td>0.147914</td>\n",
              "      <td>-0.632348</td>\n",
              "      <td>-1.910552</td>\n",
              "      <td>-0.156025</td>\n",
              "      <td>-0.454087</td>\n",
              "      <td>-1.064866</td>\n",
              "      <td>-1.379529</td>\n",
              "      <td>-0.581117</td>\n",
              "      <td>-0.480311</td>\n",
              "      <td>0.074081</td>\n",
              "      <td>-0.096435</td>\n",
              "      <td>0.397481</td>\n",
              "      <td>-1.680023</td>\n",
              "      <td>-2.375595</td>\n",
              "      <td>-0.046611</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>1.896792</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>-0.447691</td>\n",
              "      <td>-0.345135</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>1.353125</td>\n",
              "      <td>2.701283</td>\n",
              "      <td>2.879588</td>\n",
              "      <td>1.216861</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>-0.356429</td>\n",
              "      <td>0.655815</td>\n",
              "      <td>0.955338</td>\n",
              "      <td>1.008674</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>0.292360</td>\n",
              "      <td>0.559189</td>\n",
              "      <td>0.383569</td>\n",
              "      <td>1.198075</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.133987</td>\n",
              "      <td>0.792040</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.010000e+14</td>\n",
              "      <td>69</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.284237</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.204774</td>\n",
              "      <td>-1.606555</td>\n",
              "      <td>-1.645568</td>\n",
              "      <td>-1.391039</td>\n",
              "      <td>-0.884223</td>\n",
              "      <td>-1.777544</td>\n",
              "      <td>-1.383460</td>\n",
              "      <td>0.374985</td>\n",
              "      <td>-1.600285</td>\n",
              "      <td>-1.286055</td>\n",
              "      <td>-1.932946</td>\n",
              "      <td>-2.282337</td>\n",
              "      <td>-1.270281</td>\n",
              "      <td>-1.329469</td>\n",
              "      <td>-1.680023</td>\n",
              "      <td>-0.147494</td>\n",
              "      <td>-1.278338</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>-2.475944</td>\n",
              "      <td>-0.526629</td>\n",
              "      <td>-1.050995</td>\n",
              "      <td>-1.893202</td>\n",
              "      <td>-0.930366</td>\n",
              "      <td>1.353125</td>\n",
              "      <td>0.313175</td>\n",
              "      <td>0.120177</td>\n",
              "      <td>1.373926</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>-0.645605</td>\n",
              "      <td>-1.186377</td>\n",
              "      <td>-0.610361</td>\n",
              "      <td>-0.554608</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>1.594513</td>\n",
              "      <td>0.744560</td>\n",
              "      <td>-0.232412</td>\n",
              "      <td>-0.756372</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.653059</td>\n",
              "      <td>0.792040</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.010000e+14</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.604934</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>-0.142308</td>\n",
              "      <td>0.563687</td>\n",
              "      <td>0.070145</td>\n",
              "      <td>1.068803</td>\n",
              "      <td>0.641127</td>\n",
              "      <td>-0.420292</td>\n",
              "      <td>0.532354</td>\n",
              "      <td>-0.838283</td>\n",
              "      <td>0.468456</td>\n",
              "      <td>0.441080</td>\n",
              "      <td>0.799132</td>\n",
              "      <td>1.077411</td>\n",
              "      <td>-0.034257</td>\n",
              "      <td>0.841551</td>\n",
              "      <td>0.489107</td>\n",
              "      <td>-0.046611</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>1.678155</td>\n",
              "      <td>-0.526629</td>\n",
              "      <td>-0.146039</td>\n",
              "      <td>0.502703</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>0.323708</td>\n",
              "      <td>0.006446</td>\n",
              "      <td>-0.332860</td>\n",
              "      <td>-0.942781</td>\n",
              "      <td>-0.911756</td>\n",
              "      <td>0.278611</td>\n",
              "      <td>-0.201368</td>\n",
              "      <td>-0.366011</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>2.487176</td>\n",
              "      <td>1.594513</td>\n",
              "      <td>1.486043</td>\n",
              "      <td>0.075578</td>\n",
              "      <td>-1.366296</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.708077</td>\n",
              "      <td>1.559219</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.010000e+14</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.600905</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.990363</td>\n",
              "      <td>-2.100478</td>\n",
              "      <td>-3.826531</td>\n",
              "      <td>-2.292311</td>\n",
              "      <td>-1.910552</td>\n",
              "      <td>-2.412544</td>\n",
              "      <td>-1.563702</td>\n",
              "      <td>-3.601887</td>\n",
              "      <td>-2.172907</td>\n",
              "      <td>-1.575260</td>\n",
              "      <td>-3.168594</td>\n",
              "      <td>-3.913703</td>\n",
              "      <td>-2.248486</td>\n",
              "      <td>-1.329469</td>\n",
              "      <td>-4.481773</td>\n",
              "      <td>-2.375595</td>\n",
              "      <td>-1.278338</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>-2.475944</td>\n",
              "      <td>-4.166230</td>\n",
              "      <td>-2.257604</td>\n",
              "      <td>-3.742814</td>\n",
              "      <td>2.245092</td>\n",
              "      <td>1.626308</td>\n",
              "      <td>1.824913</td>\n",
              "      <td>1.602846</td>\n",
              "      <td>-0.118190</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>-1.601020</td>\n",
              "      <td>-1.293361</td>\n",
              "      <td>-0.634741</td>\n",
              "      <td>-0.496854</td>\n",
              "      <td>4.320914</td>\n",
              "      <td>4.575097</td>\n",
              "      <td>4.380948</td>\n",
              "      <td>3.333670</td>\n",
              "      <td>-4.034716</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.971600</td>\n",
              "      <td>-1.871389</td>\n",
              "      <td>0.400807</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.010000e+14</td>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.612809</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>1.543163</td>\n",
              "      <td>1.241470</td>\n",
              "      <td>0.564491</td>\n",
              "      <td>1.175637</td>\n",
              "      <td>1.000583</td>\n",
              "      <td>-0.026012</td>\n",
              "      <td>0.122018</td>\n",
              "      <td>1.053274</td>\n",
              "      <td>1.925326</td>\n",
              "      <td>1.393470</td>\n",
              "      <td>0.617869</td>\n",
              "      <td>0.881770</td>\n",
              "      <td>-0.465994</td>\n",
              "      <td>0.841551</td>\n",
              "      <td>-0.147494</td>\n",
              "      <td>1.800981</td>\n",
              "      <td>1.745199</td>\n",
              "      <td>1.022244</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>0.155613</td>\n",
              "      <td>1.057464</td>\n",
              "      <td>1.615559</td>\n",
              "      <td>-1.735126</td>\n",
              "      <td>-0.716560</td>\n",
              "      <td>-1.321305</td>\n",
              "      <td>-2.081502</td>\n",
              "      <td>-0.911756</td>\n",
              "      <td>1.231169</td>\n",
              "      <td>0.152032</td>\n",
              "      <td>-0.459632</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>-0.575743</td>\n",
              "      <td>0.744560</td>\n",
              "      <td>-0.848393</td>\n",
              "      <td>-0.369041</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.921032</td>\n",
              "      <td>0.024861</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>1.362430e+14</td>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.663388</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.449873</td>\n",
              "      <td>-0.491669</td>\n",
              "      <td>-0.550781</td>\n",
              "      <td>-0.778050</td>\n",
              "      <td>-0.138784</td>\n",
              "      <td>-0.786490</td>\n",
              "      <td>-0.803306</td>\n",
              "      <td>0.169082</td>\n",
              "      <td>0.295754</td>\n",
              "      <td>-1.367996</td>\n",
              "      <td>-0.758225</td>\n",
              "      <td>-1.376023</td>\n",
              "      <td>-0.487717</td>\n",
              "      <td>-0.897731</td>\n",
              "      <td>0.561376</td>\n",
              "      <td>-0.465794</td>\n",
              "      <td>-1.278338</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>0.803608</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>-1.654300</td>\n",
              "      <td>-0.717989</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>2.382542</td>\n",
              "      <td>0.641814</td>\n",
              "      <td>0.902697</td>\n",
              "      <td>-0.235989</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>-1.869941</td>\n",
              "      <td>-1.772871</td>\n",
              "      <td>-1.276004</td>\n",
              "      <td>-1.326649</td>\n",
              "      <td>0.844282</td>\n",
              "      <td>0.726411</td>\n",
              "      <td>-0.367666</td>\n",
              "      <td>3.155483</td>\n",
              "      <td>-2.506017</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.653059</td>\n",
              "      <td>-0.742318</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>1.362430e+14</td>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.683246</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>1.176280</td>\n",
              "      <td>0.619041</td>\n",
              "      <td>0.249150</td>\n",
              "      <td>1.328086</td>\n",
              "      <td>0.585565</td>\n",
              "      <td>0.314195</td>\n",
              "      <td>-0.036821</td>\n",
              "      <td>1.001726</td>\n",
              "      <td>1.232439</td>\n",
              "      <td>1.156174</td>\n",
              "      <td>1.161658</td>\n",
              "      <td>0.490488</td>\n",
              "      <td>-0.034257</td>\n",
              "      <td>1.121726</td>\n",
              "      <td>-0.784094</td>\n",
              "      <td>0.569253</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>-0.945487</td>\n",
              "      <td>-0.526629</td>\n",
              "      <td>-1.352648</td>\n",
              "      <td>-0.153822</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>2.382542</td>\n",
              "      <td>0.554177</td>\n",
              "      <td>0.779141</td>\n",
              "      <td>-0.432320</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>1.728618</td>\n",
              "      <td>1.212232</td>\n",
              "      <td>0.281518</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>0.296650</td>\n",
              "      <td>-0.575743</td>\n",
              "      <td>1.115301</td>\n",
              "      <td>2.231511</td>\n",
              "      <td>-2.221087</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.653059</td>\n",
              "      <td>-0.742318</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>1.362430e+14</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.452949</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.192931</td>\n",
              "      <td>0.028539</td>\n",
              "      <td>1.187346</td>\n",
              "      <td>0.987028</td>\n",
              "      <td>-0.884223</td>\n",
              "      <td>1.100369</td>\n",
              "      <td>0.940536</td>\n",
              "      <td>0.374985</td>\n",
              "      <td>0.667790</td>\n",
              "      <td>-0.555812</td>\n",
              "      <td>0.181338</td>\n",
              "      <td>-0.288445</td>\n",
              "      <td>1.077411</td>\n",
              "      <td>0.829218</td>\n",
              "      <td>1.121726</td>\n",
              "      <td>-0.147494</td>\n",
              "      <td>1.185117</td>\n",
              "      <td>0.503414</td>\n",
              "      <td>2.334065</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>-1.352648</td>\n",
              "      <td>0.881271</td>\n",
              "      <td>-0.930366</td>\n",
              "      <td>-0.705709</td>\n",
              "      <td>0.817088</td>\n",
              "      <td>1.438105</td>\n",
              "      <td>-1.492508</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>0.543210</td>\n",
              "      <td>0.648296</td>\n",
              "      <td>0.386299</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>-1.009794</td>\n",
              "      <td>-1.294520</td>\n",
              "      <td>-0.848393</td>\n",
              "      <td>0.343285</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.921032</td>\n",
              "      <td>0.792040</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>1.362430e+14</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.318083</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.621322</td>\n",
              "      <td>-0.843219</td>\n",
              "      <td>-0.411780</td>\n",
              "      <td>-1.242215</td>\n",
              "      <td>-0.884223</td>\n",
              "      <td>-1.062034</td>\n",
              "      <td>-1.124362</td>\n",
              "      <td>-2.162036</td>\n",
              "      <td>-0.412459</td>\n",
              "      <td>-1.189653</td>\n",
              "      <td>-0.946351</td>\n",
              "      <td>-0.650971</td>\n",
              "      <td>-1.074640</td>\n",
              "      <td>-1.329469</td>\n",
              "      <td>-1.680023</td>\n",
              "      <td>-0.147494</td>\n",
              "      <td>-0.662475</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>-0.945487</td>\n",
              "      <td>-0.526629</td>\n",
              "      <td>-0.447691</td>\n",
              "      <td>-1.215223</td>\n",
              "      <td>1.615559</td>\n",
              "      <td>1.353125</td>\n",
              "      <td>-1.110926</td>\n",
              "      <td>-0.044563</td>\n",
              "      <td>4.044030</td>\n",
              "      <td>-0.911756</td>\n",
              "      <td>0.807810</td>\n",
              "      <td>1.084407</td>\n",
              "      <td>0.675626</td>\n",
              "      <td>1.008674</td>\n",
              "      <td>0.844282</td>\n",
              "      <td>1.160462</td>\n",
              "      <td>1.233061</td>\n",
              "      <td>1.615530</td>\n",
              "      <td>-1.101755</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.440104</td>\n",
              "      <td>-1.509497</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>1.362430e+14</td>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.680824</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>1.301130</td>\n",
              "      <td>1.364480</td>\n",
              "      <td>1.745719</td>\n",
              "      <td>1.881463</td>\n",
              "      <td>1.625378</td>\n",
              "      <td>1.579269</td>\n",
              "      <td>1.403030</td>\n",
              "      <td>0.798900</td>\n",
              "      <td>1.537309</td>\n",
              "      <td>1.715209</td>\n",
              "      <td>1.161658</td>\n",
              "      <td>1.664334</td>\n",
              "      <td>0.829218</td>\n",
              "      <td>1.121726</td>\n",
              "      <td>1.444007</td>\n",
              "      <td>1.185117</td>\n",
              "      <td>1.124306</td>\n",
              "      <td>1.459518</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>-0.146039</td>\n",
              "      <td>1.559968</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>-0.705709</td>\n",
              "      <td>-0.957561</td>\n",
              "      <td>-0.703527</td>\n",
              "      <td>-0.746450</td>\n",
              "      <td>-0.911756</td>\n",
              "      <td>0.469123</td>\n",
              "      <td>0.189628</td>\n",
              "      <td>-0.049886</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>-1.009794</td>\n",
              "      <td>-1.665262</td>\n",
              "      <td>-0.848393</td>\n",
              "      <td>-0.084111</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.133987</td>\n",
              "      <td>0.024861</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4096 rows × 64 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b1971c7-d6a8-4e87-be6e-0e157daca7d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b1971c7-d6a8-4e87-be6e-0e157daca7d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b1971c7-d6a8-4e87-be6e-0e157daca7d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          prim_key  r1agey  ragender  ...  r1rs7412  r1rs429358  r1cdr_final\n",
              "0     1.010000e+14      68         2  ...      -1.0        -1.0          0.5\n",
              "1     1.010000e+14      69         2  ...      -1.0        -1.0          1.0\n",
              "2     1.010000e+14      61         1  ...      -1.0        -1.0          0.5\n",
              "3     1.010000e+14      61         1  ...      -1.0        -1.0          2.0\n",
              "4     1.010000e+14      69         1  ...      -1.0        -1.0          0.5\n",
              "...            ...     ...       ...  ...       ...         ...          ...\n",
              "4091  1.362430e+14      80         2  ...      -1.0        -1.0          0.5\n",
              "4092  1.362430e+14      65         1  ...      -1.0        -1.0          0.0\n",
              "4093  1.362430e+14      62         1  ...      -1.0        -1.0          0.0\n",
              "4094  1.362430e+14      60         2  ...      -1.0        -1.0          0.5\n",
              "4095  1.362430e+14      69         1  ...      -1.0        -1.0          0.0\n",
              "\n",
              "[4096 rows x 64 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(training_data):\n",
        "    import math\n",
        "    from sklearn import preprocessing\n",
        "    labels = training_data[['r1cdr_final']]\n",
        "    labelsencoded = labels.apply(preprocessing.LabelEncoder().fit_transform)\n",
        "    training_data = training_data.drop(columns=['prim_key', 'r1cdr_final'])\n",
        "    training_data2 = training_data.apply(preprocessing.LabelEncoder().fit_transform) \n",
        "\n",
        "    X_train, X_val,Y_train, Y_val = train_test_split(training_data,labelsencoded,test_size=0.25,random_state=40)\n",
        "    X_train2, X_val2,Y_train2, Y_val2 = train_test_split(training_data2,labelsencoded,test_size=0.25,random_state=40)\n",
        "\n",
        "    return training_data, X_train, X_val, Y_train, Y_val, training_data2, X_train2, X_val2, Y_train2, Y_val2, labelsencoded"
      ],
      "metadata": {
        "id": "SLyvL0cb-eyN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **training_data is the raw data (with int/float values)**\n",
        "## **training_data2 is label encoded data (with encoded values (int))**"
      ],
      "metadata": {
        "id": "lE5EasNsk6kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, X_train, X_val, Y_train, Y_val, training_data2, X_train2, X_val2, Y_train2, Y_val2, labelsencoded = preprocessing(training_data)\n",
        "display(training_data)\n",
        "display(training_data2)\n",
        "display(labelsencoded)"
      ],
      "metadata": {
        "id": "h4m6j31D-e4D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49976921-ce1d-42ef-a233-9b05c48d09f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-62509c92-0fd2-4068-bf3f-3109c166dcda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r1agey</th>\n",
              "      <th>ragender</th>\n",
              "      <th>raedyrs</th>\n",
              "      <th>h1rural</th>\n",
              "      <th>r1location</th>\n",
              "      <th>r1wtresp</th>\n",
              "      <th>r1obsnoise</th>\n",
              "      <th>r1obsodor</th>\n",
              "      <th>r1obsair</th>\n",
              "      <th>r1obshouse</th>\n",
              "      <th>r1borient</th>\n",
              "      <th>r1bexefu</th>\n",
              "      <th>r1blangf</th>\n",
              "      <th>r1bmemory</th>\n",
              "      <th>r1bvsp</th>\n",
              "      <th>r1nmemimm</th>\n",
              "      <th>r1nmemdel</th>\n",
              "      <th>r1nmemrec</th>\n",
              "      <th>r1nreason</th>\n",
              "      <th>r1natnspd</th>\n",
              "      <th>r1sgcp</th>\n",
              "      <th>r1hmse_scorz</th>\n",
              "      <th>r1word_totaz</th>\n",
              "      <th>r1word_dz</th>\n",
              "      <th>r1wre_scorez</th>\n",
              "      <th>r1log_recoz</th>\n",
              "      <th>r1bm_immexz</th>\n",
              "      <th>r1bm_reclexz</th>\n",
              "      <th>r1verbalz</th>\n",
              "      <th>r1csid_scorz</th>\n",
              "      <th>r1rv_scorez</th>\n",
              "      <th>r1cog_totalz</th>\n",
              "      <th>r1i_hear</th>\n",
              "      <th>r1i_sleep</th>\n",
              "      <th>r1systo</th>\n",
              "      <th>r1diasto</th>\n",
              "      <th>r1pulse</th>\n",
              "      <th>r1bphigh</th>\n",
              "      <th>r1mheight</th>\n",
              "      <th>r1mweight</th>\n",
              "      <th>r1mbmi</th>\n",
              "      <th>r1bmicat</th>\n",
              "      <th>r1adla_d</th>\n",
              "      <th>r1iadltot1_d</th>\n",
              "      <th>r1cesd10</th>\n",
              "      <th>r1anx5</th>\n",
              "      <th>r1mna_scale</th>\n",
              "      <th>r1spice</th>\n",
              "      <th>r1hear_r</th>\n",
              "      <th>r1hear_l</th>\n",
              "      <th>r1hear_aid</th>\n",
              "      <th>r1prs_toplam</th>\n",
              "      <th>r1prs_topkun</th>\n",
              "      <th>r1prs_topjan</th>\n",
              "      <th>r1prs_topcog</th>\n",
              "      <th>r1prs_pc1</th>\n",
              "      <th>r1prs_pc2</th>\n",
              "      <th>r1prs_pc3</th>\n",
              "      <th>r1prs_pc4</th>\n",
              "      <th>r1prs_pc5</th>\n",
              "      <th>r1rs7412</th>\n",
              "      <th>r1rs429358</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.484271</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>-1.010781</td>\n",
              "      <td>0.147914</td>\n",
              "      <td>-0.632348</td>\n",
              "      <td>-1.910552</td>\n",
              "      <td>-0.156025</td>\n",
              "      <td>-0.454087</td>\n",
              "      <td>-1.064866</td>\n",
              "      <td>-1.379529</td>\n",
              "      <td>-0.581117</td>\n",
              "      <td>-0.480311</td>\n",
              "      <td>0.074081</td>\n",
              "      <td>-0.096435</td>\n",
              "      <td>0.397481</td>\n",
              "      <td>-1.680023</td>\n",
              "      <td>-2.375595</td>\n",
              "      <td>-0.046611</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>1.896792</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>-0.447691</td>\n",
              "      <td>-0.345135</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>1.353125</td>\n",
              "      <td>2.701283</td>\n",
              "      <td>2.879588</td>\n",
              "      <td>1.216861</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>-0.356429</td>\n",
              "      <td>0.655815</td>\n",
              "      <td>0.955338</td>\n",
              "      <td>1.008674</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>0.292360</td>\n",
              "      <td>0.559189</td>\n",
              "      <td>0.383569</td>\n",
              "      <td>1.198075</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.133987</td>\n",
              "      <td>0.792040</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.284237</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.204774</td>\n",
              "      <td>-1.606555</td>\n",
              "      <td>-1.645568</td>\n",
              "      <td>-1.391039</td>\n",
              "      <td>-0.884223</td>\n",
              "      <td>-1.777544</td>\n",
              "      <td>-1.383460</td>\n",
              "      <td>0.374985</td>\n",
              "      <td>-1.600285</td>\n",
              "      <td>-1.286055</td>\n",
              "      <td>-1.932946</td>\n",
              "      <td>-2.282337</td>\n",
              "      <td>-1.270281</td>\n",
              "      <td>-1.329469</td>\n",
              "      <td>-1.680023</td>\n",
              "      <td>-0.147494</td>\n",
              "      <td>-1.278338</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>-2.475944</td>\n",
              "      <td>-0.526629</td>\n",
              "      <td>-1.050995</td>\n",
              "      <td>-1.893202</td>\n",
              "      <td>-0.930366</td>\n",
              "      <td>1.353125</td>\n",
              "      <td>0.313175</td>\n",
              "      <td>0.120177</td>\n",
              "      <td>1.373926</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>-0.645605</td>\n",
              "      <td>-1.186377</td>\n",
              "      <td>-0.610361</td>\n",
              "      <td>-0.554608</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>1.594513</td>\n",
              "      <td>0.744560</td>\n",
              "      <td>-0.232412</td>\n",
              "      <td>-0.756372</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.653059</td>\n",
              "      <td>0.792040</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.604934</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>-0.142308</td>\n",
              "      <td>0.563687</td>\n",
              "      <td>0.070145</td>\n",
              "      <td>1.068803</td>\n",
              "      <td>0.641127</td>\n",
              "      <td>-0.420292</td>\n",
              "      <td>0.532354</td>\n",
              "      <td>-0.838283</td>\n",
              "      <td>0.468456</td>\n",
              "      <td>0.441080</td>\n",
              "      <td>0.799132</td>\n",
              "      <td>1.077411</td>\n",
              "      <td>-0.034257</td>\n",
              "      <td>0.841551</td>\n",
              "      <td>0.489107</td>\n",
              "      <td>-0.046611</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>1.678155</td>\n",
              "      <td>-0.526629</td>\n",
              "      <td>-0.146039</td>\n",
              "      <td>0.502703</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>0.323708</td>\n",
              "      <td>0.006446</td>\n",
              "      <td>-0.332860</td>\n",
              "      <td>-0.942781</td>\n",
              "      <td>-0.911756</td>\n",
              "      <td>0.278611</td>\n",
              "      <td>-0.201368</td>\n",
              "      <td>-0.366011</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>2.487176</td>\n",
              "      <td>1.594513</td>\n",
              "      <td>1.486043</td>\n",
              "      <td>0.075578</td>\n",
              "      <td>-1.366296</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.708077</td>\n",
              "      <td>1.559219</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.600905</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-2.990363</td>\n",
              "      <td>-2.100478</td>\n",
              "      <td>-3.826531</td>\n",
              "      <td>-2.292311</td>\n",
              "      <td>-1.910552</td>\n",
              "      <td>-2.412544</td>\n",
              "      <td>-1.563702</td>\n",
              "      <td>-3.601887</td>\n",
              "      <td>-2.172907</td>\n",
              "      <td>-1.575260</td>\n",
              "      <td>-3.168594</td>\n",
              "      <td>-3.913703</td>\n",
              "      <td>-2.248486</td>\n",
              "      <td>-1.329469</td>\n",
              "      <td>-4.481773</td>\n",
              "      <td>-2.375595</td>\n",
              "      <td>-1.278338</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>-2.475944</td>\n",
              "      <td>-4.166230</td>\n",
              "      <td>-2.257604</td>\n",
              "      <td>-3.742814</td>\n",
              "      <td>2.245092</td>\n",
              "      <td>1.626308</td>\n",
              "      <td>1.824913</td>\n",
              "      <td>1.602846</td>\n",
              "      <td>-0.118190</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>-1.601020</td>\n",
              "      <td>-1.293361</td>\n",
              "      <td>-0.634741</td>\n",
              "      <td>-0.496854</td>\n",
              "      <td>4.320914</td>\n",
              "      <td>4.575097</td>\n",
              "      <td>4.380948</td>\n",
              "      <td>3.333670</td>\n",
              "      <td>-4.034716</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.971600</td>\n",
              "      <td>-1.871389</td>\n",
              "      <td>0.400807</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.612809</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>1.543163</td>\n",
              "      <td>1.241470</td>\n",
              "      <td>0.564491</td>\n",
              "      <td>1.175637</td>\n",
              "      <td>1.000583</td>\n",
              "      <td>-0.026012</td>\n",
              "      <td>0.122018</td>\n",
              "      <td>1.053274</td>\n",
              "      <td>1.925326</td>\n",
              "      <td>1.393470</td>\n",
              "      <td>0.617869</td>\n",
              "      <td>0.881770</td>\n",
              "      <td>-0.465994</td>\n",
              "      <td>0.841551</td>\n",
              "      <td>-0.147494</td>\n",
              "      <td>1.800981</td>\n",
              "      <td>1.745199</td>\n",
              "      <td>1.022244</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>0.155613</td>\n",
              "      <td>1.057464</td>\n",
              "      <td>1.615559</td>\n",
              "      <td>-1.735126</td>\n",
              "      <td>-0.716560</td>\n",
              "      <td>-1.321305</td>\n",
              "      <td>-2.081502</td>\n",
              "      <td>-0.911756</td>\n",
              "      <td>1.231169</td>\n",
              "      <td>0.152032</td>\n",
              "      <td>-0.459632</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>-0.575743</td>\n",
              "      <td>0.744560</td>\n",
              "      <td>-0.848393</td>\n",
              "      <td>-0.369041</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.921032</td>\n",
              "      <td>0.024861</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>80</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.663388</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.449873</td>\n",
              "      <td>-0.491669</td>\n",
              "      <td>-0.550781</td>\n",
              "      <td>-0.778050</td>\n",
              "      <td>-0.138784</td>\n",
              "      <td>-0.786490</td>\n",
              "      <td>-0.803306</td>\n",
              "      <td>0.169082</td>\n",
              "      <td>0.295754</td>\n",
              "      <td>-1.367996</td>\n",
              "      <td>-0.758225</td>\n",
              "      <td>-1.376023</td>\n",
              "      <td>-0.487717</td>\n",
              "      <td>-0.897731</td>\n",
              "      <td>0.561376</td>\n",
              "      <td>-0.465794</td>\n",
              "      <td>-1.278338</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>0.803608</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>-1.654300</td>\n",
              "      <td>-0.717989</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>2.382542</td>\n",
              "      <td>0.641814</td>\n",
              "      <td>0.902697</td>\n",
              "      <td>-0.235989</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>-1.869941</td>\n",
              "      <td>-1.772871</td>\n",
              "      <td>-1.276004</td>\n",
              "      <td>-1.326649</td>\n",
              "      <td>0.844282</td>\n",
              "      <td>0.726411</td>\n",
              "      <td>-0.367666</td>\n",
              "      <td>3.155483</td>\n",
              "      <td>-2.506017</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.653059</td>\n",
              "      <td>-0.742318</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.683246</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>1.176280</td>\n",
              "      <td>0.619041</td>\n",
              "      <td>0.249150</td>\n",
              "      <td>1.328086</td>\n",
              "      <td>0.585565</td>\n",
              "      <td>0.314195</td>\n",
              "      <td>-0.036821</td>\n",
              "      <td>1.001726</td>\n",
              "      <td>1.232439</td>\n",
              "      <td>1.156174</td>\n",
              "      <td>1.161658</td>\n",
              "      <td>0.490488</td>\n",
              "      <td>-0.034257</td>\n",
              "      <td>1.121726</td>\n",
              "      <td>-0.784094</td>\n",
              "      <td>0.569253</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>-0.945487</td>\n",
              "      <td>-0.526629</td>\n",
              "      <td>-1.352648</td>\n",
              "      <td>-0.153822</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>2.382542</td>\n",
              "      <td>0.554177</td>\n",
              "      <td>0.779141</td>\n",
              "      <td>-0.432320</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>1.728618</td>\n",
              "      <td>1.212232</td>\n",
              "      <td>0.281518</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>0.296650</td>\n",
              "      <td>-0.575743</td>\n",
              "      <td>1.115301</td>\n",
              "      <td>2.231511</td>\n",
              "      <td>-2.221087</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.653059</td>\n",
              "      <td>-0.742318</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.452949</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.192931</td>\n",
              "      <td>0.028539</td>\n",
              "      <td>1.187346</td>\n",
              "      <td>0.987028</td>\n",
              "      <td>-0.884223</td>\n",
              "      <td>1.100369</td>\n",
              "      <td>0.940536</td>\n",
              "      <td>0.374985</td>\n",
              "      <td>0.667790</td>\n",
              "      <td>-0.555812</td>\n",
              "      <td>0.181338</td>\n",
              "      <td>-0.288445</td>\n",
              "      <td>1.077411</td>\n",
              "      <td>0.829218</td>\n",
              "      <td>1.121726</td>\n",
              "      <td>-0.147494</td>\n",
              "      <td>1.185117</td>\n",
              "      <td>0.503414</td>\n",
              "      <td>2.334065</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>-1.352648</td>\n",
              "      <td>0.881271</td>\n",
              "      <td>-0.930366</td>\n",
              "      <td>-0.705709</td>\n",
              "      <td>0.817088</td>\n",
              "      <td>1.438105</td>\n",
              "      <td>-1.492508</td>\n",
              "      <td>1.096511</td>\n",
              "      <td>0.543210</td>\n",
              "      <td>0.648296</td>\n",
              "      <td>0.386299</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>-1.009794</td>\n",
              "      <td>-1.294520</td>\n",
              "      <td>-0.848393</td>\n",
              "      <td>0.343285</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.921032</td>\n",
              "      <td>0.792040</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-1.318083</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.621322</td>\n",
              "      <td>-0.843219</td>\n",
              "      <td>-0.411780</td>\n",
              "      <td>-1.242215</td>\n",
              "      <td>-0.884223</td>\n",
              "      <td>-1.062034</td>\n",
              "      <td>-1.124362</td>\n",
              "      <td>-2.162036</td>\n",
              "      <td>-0.412459</td>\n",
              "      <td>-1.189653</td>\n",
              "      <td>-0.946351</td>\n",
              "      <td>-0.650971</td>\n",
              "      <td>-1.074640</td>\n",
              "      <td>-1.329469</td>\n",
              "      <td>-1.680023</td>\n",
              "      <td>-0.147494</td>\n",
              "      <td>-0.662475</td>\n",
              "      <td>-0.738371</td>\n",
              "      <td>-0.945487</td>\n",
              "      <td>-0.526629</td>\n",
              "      <td>-0.447691</td>\n",
              "      <td>-1.215223</td>\n",
              "      <td>1.615559</td>\n",
              "      <td>1.353125</td>\n",
              "      <td>-1.110926</td>\n",
              "      <td>-0.044563</td>\n",
              "      <td>4.044030</td>\n",
              "      <td>-0.911756</td>\n",
              "      <td>0.807810</td>\n",
              "      <td>1.084407</td>\n",
              "      <td>0.675626</td>\n",
              "      <td>1.008674</td>\n",
              "      <td>0.844282</td>\n",
              "      <td>1.160462</td>\n",
              "      <td>1.233061</td>\n",
              "      <td>1.615530</td>\n",
              "      <td>-1.101755</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.440104</td>\n",
              "      <td>-1.509497</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>69</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.680824</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.212536</td>\n",
              "      <td>1.301130</td>\n",
              "      <td>1.364480</td>\n",
              "      <td>1.745719</td>\n",
              "      <td>1.881463</td>\n",
              "      <td>1.625378</td>\n",
              "      <td>1.579269</td>\n",
              "      <td>1.403030</td>\n",
              "      <td>0.798900</td>\n",
              "      <td>1.537309</td>\n",
              "      <td>1.715209</td>\n",
              "      <td>1.161658</td>\n",
              "      <td>1.664334</td>\n",
              "      <td>0.829218</td>\n",
              "      <td>1.121726</td>\n",
              "      <td>1.444007</td>\n",
              "      <td>1.185117</td>\n",
              "      <td>1.124306</td>\n",
              "      <td>1.459518</td>\n",
              "      <td>0.686572</td>\n",
              "      <td>-0.146039</td>\n",
              "      <td>1.559968</td>\n",
              "      <td>0.766917</td>\n",
              "      <td>-0.705709</td>\n",
              "      <td>-0.957561</td>\n",
              "      <td>-0.703527</td>\n",
              "      <td>-0.746450</td>\n",
              "      <td>-0.911756</td>\n",
              "      <td>0.469123</td>\n",
              "      <td>0.189628</td>\n",
              "      <td>-0.049886</td>\n",
              "      <td>-0.158987</td>\n",
              "      <td>-0.798612</td>\n",
              "      <td>-1.009794</td>\n",
              "      <td>-1.665262</td>\n",
              "      <td>-0.848393</td>\n",
              "      <td>-0.084111</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.133987</td>\n",
              "      <td>0.024861</td>\n",
              "      <td>-0.084613</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4096 rows × 62 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62509c92-0fd2-4068-bf3f-3109c166dcda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62509c92-0fd2-4068-bf3f-3109c166dcda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62509c92-0fd2-4068-bf3f-3109c166dcda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      r1agey  ragender  raedyrs  ...  r1prs_pc5  r1rs7412  r1rs429358\n",
              "0         68         2        0  ...       -1.0      -1.0        -1.0\n",
              "1         69         2        0  ...       -1.0      -1.0        -1.0\n",
              "2         61         1       10  ...       -1.0      -1.0        -1.0\n",
              "3         61         1        0  ...       -1.0      -1.0        -1.0\n",
              "4         69         1        8  ...       -1.0      -1.0        -1.0\n",
              "...      ...       ...      ...  ...        ...       ...         ...\n",
              "4091      80         2        0  ...       -1.0      -1.0        -1.0\n",
              "4092      65         1        9  ...       -1.0      -1.0        -1.0\n",
              "4093      62         1        0  ...       -1.0      -1.0        -1.0\n",
              "4094      60         2        5  ...       -1.0      -1.0        -1.0\n",
              "4095      69         1       10  ...       -1.0      -1.0        -1.0\n",
              "\n",
              "[4096 rows x 62 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f6546c9-bab0-4db0-b1d0-5829ff1292d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r1agey</th>\n",
              "      <th>ragender</th>\n",
              "      <th>raedyrs</th>\n",
              "      <th>h1rural</th>\n",
              "      <th>r1location</th>\n",
              "      <th>r1wtresp</th>\n",
              "      <th>r1obsnoise</th>\n",
              "      <th>r1obsodor</th>\n",
              "      <th>r1obsair</th>\n",
              "      <th>r1obshouse</th>\n",
              "      <th>r1borient</th>\n",
              "      <th>r1bexefu</th>\n",
              "      <th>r1blangf</th>\n",
              "      <th>r1bmemory</th>\n",
              "      <th>r1bvsp</th>\n",
              "      <th>r1nmemimm</th>\n",
              "      <th>r1nmemdel</th>\n",
              "      <th>r1nmemrec</th>\n",
              "      <th>r1nreason</th>\n",
              "      <th>r1natnspd</th>\n",
              "      <th>r1sgcp</th>\n",
              "      <th>r1hmse_scorz</th>\n",
              "      <th>r1word_totaz</th>\n",
              "      <th>r1word_dz</th>\n",
              "      <th>r1wre_scorez</th>\n",
              "      <th>r1log_recoz</th>\n",
              "      <th>r1bm_immexz</th>\n",
              "      <th>r1bm_reclexz</th>\n",
              "      <th>r1verbalz</th>\n",
              "      <th>r1csid_scorz</th>\n",
              "      <th>r1rv_scorez</th>\n",
              "      <th>r1cog_totalz</th>\n",
              "      <th>r1i_hear</th>\n",
              "      <th>r1i_sleep</th>\n",
              "      <th>r1systo</th>\n",
              "      <th>r1diasto</th>\n",
              "      <th>r1pulse</th>\n",
              "      <th>r1bphigh</th>\n",
              "      <th>r1mheight</th>\n",
              "      <th>r1mweight</th>\n",
              "      <th>r1mbmi</th>\n",
              "      <th>r1bmicat</th>\n",
              "      <th>r1adla_d</th>\n",
              "      <th>r1iadltot1_d</th>\n",
              "      <th>r1cesd10</th>\n",
              "      <th>r1anx5</th>\n",
              "      <th>r1mna_scale</th>\n",
              "      <th>r1spice</th>\n",
              "      <th>r1hear_r</th>\n",
              "      <th>r1hear_l</th>\n",
              "      <th>r1hear_aid</th>\n",
              "      <th>r1prs_toplam</th>\n",
              "      <th>r1prs_topkun</th>\n",
              "      <th>r1prs_topjan</th>\n",
              "      <th>r1prs_topcog</th>\n",
              "      <th>r1prs_pc1</th>\n",
              "      <th>r1prs_pc2</th>\n",
              "      <th>r1prs_pc3</th>\n",
              "      <th>r1prs_pc4</th>\n",
              "      <th>r1prs_pc5</th>\n",
              "      <th>r1rs7412</th>\n",
              "      <th>r1rs429358</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2541</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>441</td>\n",
              "      <td>390</td>\n",
              "      <td>935</td>\n",
              "      <td>725</td>\n",
              "      <td>0</td>\n",
              "      <td>677</td>\n",
              "      <td>224</td>\n",
              "      <td>70</td>\n",
              "      <td>92</td>\n",
              "      <td>108</td>\n",
              "      <td>855</td>\n",
              "      <td>23</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1425</td>\n",
              "      <td>13</td>\n",
              "      <td>1605</td>\n",
              "      <td>307</td>\n",
              "      <td>214</td>\n",
              "      <td>185</td>\n",
              "      <td>67</td>\n",
              "      <td>296</td>\n",
              "      <td>491</td>\n",
              "      <td>3404</td>\n",
              "      <td>318</td>\n",
              "      <td>5</td>\n",
              "      <td>21</td>\n",
              "      <td>104</td>\n",
              "      <td>38</td>\n",
              "      <td>508</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>181</td>\n",
              "      <td>7</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1493</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>70</td>\n",
              "      <td>188</td>\n",
              "      <td>226</td>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>5</td>\n",
              "      <td>122</td>\n",
              "      <td>43</td>\n",
              "      <td>6</td>\n",
              "      <td>71</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>1605</td>\n",
              "      <td>169</td>\n",
              "      <td>115</td>\n",
              "      <td>189</td>\n",
              "      <td>67</td>\n",
              "      <td>209</td>\n",
              "      <td>135</td>\n",
              "      <td>1191</td>\n",
              "      <td>65</td>\n",
              "      <td>5</td>\n",
              "      <td>30</td>\n",
              "      <td>117</td>\n",
              "      <td>18</td>\n",
              "      <td>184</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>181</td>\n",
              "      <td>7</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2939</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>441</td>\n",
              "      <td>1008</td>\n",
              "      <td>1057</td>\n",
              "      <td>1287</td>\n",
              "      <td>10</td>\n",
              "      <td>1127</td>\n",
              "      <td>235</td>\n",
              "      <td>126</td>\n",
              "      <td>281</td>\n",
              "      <td>480</td>\n",
              "      <td>1531</td>\n",
              "      <td>27</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2775</td>\n",
              "      <td>13</td>\n",
              "      <td>1216</td>\n",
              "      <td>148</td>\n",
              "      <td>90</td>\n",
              "      <td>44</td>\n",
              "      <td>16</td>\n",
              "      <td>483</td>\n",
              "      <td>328</td>\n",
              "      <td>1549</td>\n",
              "      <td>136</td>\n",
              "      <td>33</td>\n",
              "      <td>30</td>\n",
              "      <td>164</td>\n",
              "      <td>26</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>183</td>\n",
              "      <td>182</td>\n",
              "      <td>7</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2833</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1608</td>\n",
              "      <td>260</td>\n",
              "      <td>171</td>\n",
              "      <td>84</td>\n",
              "      <td>67</td>\n",
              "      <td>74</td>\n",
              "      <td>119</td>\n",
              "      <td>1150</td>\n",
              "      <td>74</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>208</td>\n",
              "      <td>94</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3071</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>441</td>\n",
              "      <td>2073</td>\n",
              "      <td>1173</td>\n",
              "      <td>1653</td>\n",
              "      <td>11</td>\n",
              "      <td>1304</td>\n",
              "      <td>422</td>\n",
              "      <td>114</td>\n",
              "      <td>1288</td>\n",
              "      <td>876</td>\n",
              "      <td>2123</td>\n",
              "      <td>26</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>3518</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>46</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>631</td>\n",
              "      <td>396</td>\n",
              "      <td>1409</td>\n",
              "      <td>136</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>117</td>\n",
              "      <td>3</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>182</td>\n",
              "      <td>132</td>\n",
              "      <td>7</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1323</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>70</td>\n",
              "      <td>748</td>\n",
              "      <td>658</td>\n",
              "      <td>610</td>\n",
              "      <td>3</td>\n",
              "      <td>382</td>\n",
              "      <td>105</td>\n",
              "      <td>116</td>\n",
              "      <td>920</td>\n",
              "      <td>4</td>\n",
              "      <td>643</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>940</td>\n",
              "      <td>13</td>\n",
              "      <td>1610</td>\n",
              "      <td>192</td>\n",
              "      <td>146</td>\n",
              "      <td>69</td>\n",
              "      <td>67</td>\n",
              "      <td>49</td>\n",
              "      <td>46</td>\n",
              "      <td>282</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>25</td>\n",
              "      <td>29</td>\n",
              "      <td>93</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1030</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>441</td>\n",
              "      <td>1882</td>\n",
              "      <td>1071</td>\n",
              "      <td>1425</td>\n",
              "      <td>12</td>\n",
              "      <td>1098</td>\n",
              "      <td>598</td>\n",
              "      <td>110</td>\n",
              "      <td>1268</td>\n",
              "      <td>755</td>\n",
              "      <td>1993</td>\n",
              "      <td>29</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1719</td>\n",
              "      <td>13</td>\n",
              "      <td>1610</td>\n",
              "      <td>186</td>\n",
              "      <td>142</td>\n",
              "      <td>57</td>\n",
              "      <td>67</td>\n",
              "      <td>677</td>\n",
              "      <td>576</td>\n",
              "      <td>2649</td>\n",
              "      <td>136</td>\n",
              "      <td>19</td>\n",
              "      <td>7</td>\n",
              "      <td>144</td>\n",
              "      <td>88</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2108</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>329</td>\n",
              "      <td>1135</td>\n",
              "      <td>1169</td>\n",
              "      <td>1922</td>\n",
              "      <td>1</td>\n",
              "      <td>1358</td>\n",
              "      <td>927</td>\n",
              "      <td>122</td>\n",
              "      <td>1119</td>\n",
              "      <td>116</td>\n",
              "      <td>1345</td>\n",
              "      <td>21</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3309</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>202</td>\n",
              "      <td>166</td>\n",
              "      <td>30</td>\n",
              "      <td>67</td>\n",
              "      <td>543</td>\n",
              "      <td>490</td>\n",
              "      <td>2779</td>\n",
              "      <td>136</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>411</td>\n",
              "      <td>0</td>\n",
              "      <td>182</td>\n",
              "      <td>181</td>\n",
              "      <td>7</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>243</td>\n",
              "      <td>493</td>\n",
              "      <td>723</td>\n",
              "      <td>300</td>\n",
              "      <td>1</td>\n",
              "      <td>261</td>\n",
              "      <td>34</td>\n",
              "      <td>26</td>\n",
              "      <td>514</td>\n",
              "      <td>10</td>\n",
              "      <td>502</td>\n",
              "      <td>19</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>442</td>\n",
              "      <td>17</td>\n",
              "      <td>1605</td>\n",
              "      <td>69</td>\n",
              "      <td>105</td>\n",
              "      <td>240</td>\n",
              "      <td>16</td>\n",
              "      <td>586</td>\n",
              "      <td>556</td>\n",
              "      <td>3141</td>\n",
              "      <td>318</td>\n",
              "      <td>22</td>\n",
              "      <td>29</td>\n",
              "      <td>154</td>\n",
              "      <td>75</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1106</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>441</td>\n",
              "      <td>1952</td>\n",
              "      <td>1181</td>\n",
              "      <td>2246</td>\n",
              "      <td>13</td>\n",
              "      <td>1546</td>\n",
              "      <td>1196</td>\n",
              "      <td>144</td>\n",
              "      <td>1182</td>\n",
              "      <td>826</td>\n",
              "      <td>2282</td>\n",
              "      <td>29</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3900</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>77</td>\n",
              "      <td>75</td>\n",
              "      <td>49</td>\n",
              "      <td>16</td>\n",
              "      <td>531</td>\n",
              "      <td>403</td>\n",
              "      <td>2084</td>\n",
              "      <td>136</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>317</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>132</td>\n",
              "      <td>7</td>\n",
              "      <td>161</td>\n",
              "      <td>149</td>\n",
              "      <td>147</td>\n",
              "      <td>158</td>\n",
              "      <td>108</td>\n",
              "      <td>66</td>\n",
              "      <td>43</td>\n",
              "      <td>98</td>\n",
              "      <td>134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4096 rows × 62 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f6546c9-bab0-4db0-b1d0-5829ff1292d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f6546c9-bab0-4db0-b1d0-5829ff1292d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f6546c9-bab0-4db0-b1d0-5829ff1292d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      r1agey  ragender  raedyrs  ...  r1prs_pc5  r1rs7412  r1rs429358\n",
              "0          8         1        0  ...        134         0           0\n",
              "1          9         1        0  ...        134         0           0\n",
              "2          1         0       10  ...        134         0           0\n",
              "3          1         0        0  ...        134         0           0\n",
              "4          9         0        8  ...        134         0           0\n",
              "...      ...       ...      ...  ...        ...       ...         ...\n",
              "4091      20         1        0  ...        134         0           0\n",
              "4092       5         0        9  ...        134         0           0\n",
              "4093       2         0        0  ...        134         0           0\n",
              "4094       0         1        5  ...        134         0           0\n",
              "4095       9         0       10  ...        134         0           0\n",
              "\n",
              "[4096 rows x 62 columns]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-db890fa1-d0c4-4c65-8963-8cf1558deffd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r1cdr_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4091</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4096 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db890fa1-d0c4-4c65-8963-8cf1558deffd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db890fa1-d0c4-4c65-8963-8cf1558deffd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db890fa1-d0c4-4c65-8963-8cf1558deffd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      r1cdr_final\n",
              "0               2\n",
              "1               3\n",
              "2               2\n",
              "3               4\n",
              "4               2\n",
              "...           ...\n",
              "4091            2\n",
              "4092            1\n",
              "4093            1\n",
              "4094            2\n",
              "4095            1\n",
              "\n",
              "[4096 rows x 1 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mEW5lkaP-e7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIFeHol5Yf39"
      },
      "source": [
        "#**Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Raw data (after filling NaNs)**"
      ],
      "metadata": {
        "id": "aRyY_Hw9ll2q"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a4269f-082b-4ce7-bbf6-2b6b46804b4e",
        "id": "hBR4AfHMYf4G"
      },
      "source": [
        "model1 = LogisticRegression()\n",
        "print(\"Model 1 : Logistic Regression\", \"\\n\")\n",
        "model1.fit(X_train, Y_train)\n",
        "prediction = model1.predict(X_val)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val, prediction), \"\\n\")\n",
        "print(classification_report(Y_val, prediction), \"\\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 : Logistic Regression \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurracy of the model : 0.7802734375 \n",
            "\n",
            "Confusion matrix : \n",
            " [[380   6  25   2   0]\n",
            " [  1 101  71   0   0]\n",
            " [ 12  59 311   9   1]\n",
            " [  0   1  33   7   0]\n",
            " [  0   0   1   4   0]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.94       413\n",
            "           1       0.60      0.58      0.59       173\n",
            "           2       0.71      0.79      0.75       392\n",
            "           3       0.32      0.17      0.22        41\n",
            "           4       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.78      1024\n",
            "   macro avg       0.52      0.49      0.50      1024\n",
            "weighted avg       0.77      0.78      0.78      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded data**"
      ],
      "metadata": {
        "id": "EKReG1pPltCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modela1 = LogisticRegression()\n",
        "print(\"Model 1 : Logistic Regression\", \"\\n\")\n",
        "modela1.fit(X_train2, Y_train2)\n",
        "prediction = modela1.predict(X_val2)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val2, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val2, prediction), \"\\n\")\n",
        "print(classification_report(Y_val2, prediction), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWHMmVxml0Zw",
        "outputId": "8cdceeaf-470b-4258-c034-f7f180496b21"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 : Logistic Regression \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurracy of the model : 0.65625 \n",
            "\n",
            "Confusion matrix : \n",
            " [[284  38  87   4   0]\n",
            " [  6  94  73   0   0]\n",
            " [ 39  56 290   5   2]\n",
            " [  8   0  29   4   0]\n",
            " [  0   0   2   3   0]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.69      0.76       413\n",
            "           1       0.50      0.54      0.52       173\n",
            "           2       0.60      0.74      0.66       392\n",
            "           3       0.25      0.10      0.14        41\n",
            "           4       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.66      1024\n",
            "   macro avg       0.44      0.41      0.42      1024\n",
            "weighted avg       0.67      0.66      0.65      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBXZ9gQ0Yf4H"
      },
      "source": [
        "# **LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Raw data (after filling NaNs)**"
      ],
      "metadata": {
        "id": "bGtcaAn4qKRv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ebc1a7-4dd7-4466-c18d-d06a6c745a58",
        "id": "vX_Kme1oqKRv"
      },
      "source": [
        "model2 = LinearDiscriminantAnalysis()\n",
        "print(\"Model 2 : LinearDiscriminantAnalysis (LDA)\", \"\\n\")\n",
        "model2.fit(X_train, Y_train)\n",
        "prediction = model2.predict(X_val)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val, prediction), \"\\n\")\n",
        "print(classification_report(Y_val, prediction), \"\\n\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 : LinearDiscriminantAnalysis (LDA) \n",
            "\n",
            "Acurracy of the model : 0.765625 \n",
            "\n",
            "Confusion matrix : \n",
            " [[364   6  39   3   1   0]\n",
            " [  1 107  64   1   0   0]\n",
            " [ 11  68 303   6   3   1]\n",
            " [  0   1  31   7   2   0]\n",
            " [  0   0   1   1   3   0]\n",
            " [  0   0   0   0   0   0]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.88      0.92       413\n",
            "           1       0.59      0.62      0.60       173\n",
            "           2       0.69      0.77      0.73       392\n",
            "           3       0.39      0.17      0.24        41\n",
            "           4       0.33      0.60      0.43         5\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.77      1024\n",
            "   macro avg       0.50      0.51      0.49      1024\n",
            "weighted avg       0.77      0.77      0.77      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded data**"
      ],
      "metadata": {
        "id": "t-vpYxbiqKRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modela2 = LinearDiscriminantAnalysis()\n",
        "print(\"Model 2 : LinearDiscriminantAnalysis (LDA)\", \"\\n\")\n",
        "modela2.fit(X_train2, Y_train2)\n",
        "prediction = modela2.predict(X_val2)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val2, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val2, prediction), \"\\n\")\n",
        "print(classification_report(Y_val2, prediction), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec4fc4e-f546-4ca3-aeed-a45504c748ea",
        "id": "PeJAsbqkqKRw"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 : LinearDiscriminantAnalysis (LDA) \n",
            "\n",
            "Acurracy of the model : 0.765625 \n",
            "\n",
            "Confusion matrix : \n",
            " [[353  13  40   4   1   2]\n",
            " [  1 109  63   0   0   0]\n",
            " [ 11  61 308   7   4   1]\n",
            " [  0   1  26  11   2   1]\n",
            " [  0   0   1   1   3   0]\n",
            " [  0   0   0   0   0   0]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.85      0.91       413\n",
            "           1       0.59      0.63      0.61       173\n",
            "           2       0.70      0.79      0.74       392\n",
            "           3       0.48      0.27      0.34        41\n",
            "           4       0.30      0.60      0.40         5\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.77      1024\n",
            "   macro avg       0.51      0.52      0.50      1024\n",
            "weighted avg       0.78      0.77      0.77      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ofxjwHZYf4H"
      },
      "source": [
        "# **K Neigbors Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Raw data (after filling NaNs)**"
      ],
      "metadata": {
        "id": "hw_ob8LQq3Zb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f16980-741c-4457-e788-ccf43e046a0f",
        "id": "YxC-B3ZUq3Zj"
      },
      "source": [
        "model3 = KNeighborsClassifier()\n",
        "print(\"Model 3 : K Neighbors Classifier\", \"\\n\")\n",
        "model3.fit(X_train, Y_train)\n",
        "prediction = model3.predict(X_val)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val, prediction), \"\\n\")\n",
        "print(classification_report(Y_val, prediction), \"\\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 : K Neighbors Classifier \n",
            "\n",
            "Acurracy of the model : 0.7177734375 \n",
            "\n",
            "Confusion matrix : \n",
            " [[356  10  44   2   1]\n",
            " [  2  87  84   0   0]\n",
            " [ 19  81 285   6   1]\n",
            " [  1   1  33   5   1]\n",
            " [  0   0   2   1   2]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.86      0.90       413\n",
            "           1       0.49      0.50      0.49       173\n",
            "           2       0.64      0.73      0.68       392\n",
            "           3       0.36      0.12      0.18        41\n",
            "           4       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.72      1024\n",
            "   macro avg       0.56      0.52      0.53      1024\n",
            "weighted avg       0.72      0.72      0.72      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded data**"
      ],
      "metadata": {
        "id": "nlNbzTEHq3Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modela3 = KNeighborsClassifier()\n",
        "print(\"Model 3 : K Neighbors Classifier\", \"\\n\")\n",
        "modela3.fit(X_train2, Y_train2)\n",
        "prediction = modela3.predict(X_val2)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val2, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val2, prediction), \"\\n\")\n",
        "print(classification_report(Y_val2, prediction), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8701eab2-3f85-4231-a6e8-3c5657d458ec",
        "id": "d6htZvthq3Zj"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 : K Neighbors Classifier \n",
            "\n",
            "Acurracy of the model : 0.5859375 \n",
            "\n",
            "Confusion matrix : \n",
            " [[288  42  82   0   1]\n",
            " [ 28  81  64   0   0]\n",
            " [ 58 100 227   7   0]\n",
            " [  9   0  27   3   2]\n",
            " [  1   0   2   1   1]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.70      0.72       413\n",
            "           1       0.36      0.47      0.41       173\n",
            "           2       0.56      0.58      0.57       392\n",
            "           3       0.27      0.07      0.12        41\n",
            "           4       0.25      0.20      0.22         5\n",
            "\n",
            "    accuracy                           0.59      1024\n",
            "   macro avg       0.44      0.40      0.41      1024\n",
            "weighted avg       0.59      0.59      0.59      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHDGGDbfYf4H"
      },
      "source": [
        "# **Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Raw data (after filling NaNs)**"
      ],
      "metadata": {
        "id": "O6Cy3koerlQl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92e9d7b-c2d7-49ec-b3a3-b375eadd1f83",
        "id": "UgmYvb7prlQr"
      },
      "source": [
        "model4 = DecisionTreeClassifier()\n",
        "print(\"Model 4 : Decision Tree Classifier\", \"\\n\")\n",
        "model4.fit(X_train, Y_train)\n",
        "prediction = model4.predict(X_val)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val, prediction), \"\\n\")\n",
        "print(classification_report(Y_val, prediction), \"\\n\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 4 : Decision Tree Classifier \n",
            "\n",
            "Acurracy of the model : 0.693359375 \n",
            "\n",
            "Confusion matrix : \n",
            " [[377  10  20   6   0]\n",
            " [  1  85  80   7   0]\n",
            " [ 25 106 237  24   0]\n",
            " [  4   3  22  10   2]\n",
            " [  0   0   2   2   1]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92       413\n",
            "           1       0.42      0.49      0.45       173\n",
            "           2       0.66      0.60      0.63       392\n",
            "           3       0.20      0.24      0.22        41\n",
            "           4       0.33      0.20      0.25         5\n",
            "\n",
            "    accuracy                           0.69      1024\n",
            "   macro avg       0.51      0.49      0.49      1024\n",
            "weighted avg       0.71      0.69      0.70      1024\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Important features (importance > 1.5%)**"
      ],
      "metadata": {
        "id": "MyiRJGu-FNVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance = model4.feature_importances_\n",
        "import matplotlib.pyplot as plt\n",
        "feature_name = np.delete(col_name, [0, 63, 64])\n",
        "removal = []\n",
        "for i in range(62):\n",
        "  if importance[i] < 0.015:\n",
        "    removal.append(i)\n",
        "f_name = np.delete(feature_name, removal)\n",
        "imp = np.delete(importance, removal)\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(f_name,imp, color='b',align='center')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "EqYjePf1sQQr",
        "outputId": "7416c2a1-e334-41e0-e5e7-287f0adcb637"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded data**"
      ],
      "metadata": {
        "id": "Osgx6ZdkrlQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modela4 = DecisionTreeClassifier()\n",
        "print(\"Model 4 : Decision Tree Classifier\", \"\\n\")\n",
        "modela4.fit(X_train2, Y_train2)\n",
        "prediction = modela4.predict(X_val2)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val2, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val2, prediction), \"\\n\")\n",
        "print(classification_report(Y_val2, prediction), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df09f1cc-97e6-4906-8c7a-2df3c5ebbb97",
        "id": "iQNJSvC1rlQr"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 4 : Decision Tree Classifier \n",
            "\n",
            "Acurracy of the model : 0.6982421875 \n",
            "\n",
            "Confusion matrix : \n",
            " [[373  12  20   8   0]\n",
            " [  1  89  78   5   0]\n",
            " [ 24  98 242  26   2]\n",
            " [  3   5  21  10   2]\n",
            " [  0   0   2   2   1]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.92       413\n",
            "           1       0.44      0.51      0.47       173\n",
            "           2       0.67      0.62      0.64       392\n",
            "           3       0.20      0.24      0.22        41\n",
            "           4       0.20      0.20      0.20         5\n",
            "\n",
            "    accuracy                           0.70      1024\n",
            "   macro avg       0.49      0.50      0.49      1024\n",
            "weighted avg       0.71      0.70      0.70      1024\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Important features (importance > 1.5%)**"
      ],
      "metadata": {
        "id": "RrXlNcCkFgPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance = modela4.feature_importances_\n",
        "import matplotlib.pyplot as plt\n",
        "feature_name = np.delete(col_name, [0, 63, 64])\n",
        "removal = []\n",
        "for i in range(62):\n",
        "  if importance[i] < 0.015:\n",
        "    removal.append(i)\n",
        "f_name = np.delete(feature_name, removal)\n",
        "imp = np.delete(importance, removal)\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(f_name,imp, color='b',align='center')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "u2MDKP0kfNJg",
        "outputId": "00071b9e-9509-4b2a-e248-1a571955c4a6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gbdp34eTYf4H"
      },
      "source": [
        "# **Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Raw data (after filling NaNs)**"
      ],
      "metadata": {
        "id": "XBRDlMbnslQA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec5c386-a2de-4393-ba41-961a1966152d",
        "id": "WBluys_SslQG"
      },
      "source": [
        "model5 = RandomForestClassifier()\n",
        "print(\"Model 5 : Random Forest Classifier\", \"\\n\")\n",
        "model5.fit(X_train, Y_train)\n",
        "prediction = model5.predict(X_val)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val, prediction), \"\\n\")\n",
        "print(classification_report(Y_val, prediction), \"\\n\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 5 : Random Forest Classifier \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurracy of the model : 0.7958984375 \n",
            "\n",
            "Confusion matrix : \n",
            " [[392   3  17   1   0]\n",
            " [  1 101  71   0   0]\n",
            " [ 12  59 314   7   0]\n",
            " [  0   1  32   7   1]\n",
            " [  1   0   1   2   1]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96       413\n",
            "           1       0.62      0.58      0.60       173\n",
            "           2       0.72      0.80      0.76       392\n",
            "           3       0.41      0.17      0.24        41\n",
            "           4       0.50      0.20      0.29         5\n",
            "\n",
            "    accuracy                           0.80      1024\n",
            "   macro avg       0.64      0.54      0.57      1024\n",
            "weighted avg       0.79      0.80      0.79      1024\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Important features (importance > 2%)**"
      ],
      "metadata": {
        "id": "RQDfKTFvFh40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance = model5.feature_importances_\n",
        "import matplotlib.pyplot as plt\n",
        "feature_name = np.delete(col_name, [0, 63, 64])\n",
        "removal = []\n",
        "for i in range(62):\n",
        "  if importance[i] < 0.02:\n",
        "    removal.append(i)\n",
        "f_name = np.delete(feature_name, removal)\n",
        "imp = np.delete(importance, removal)\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(f_name,imp, color='b',align='center')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "ewZEwt9pslQH",
        "outputId": "1b8c9400-3cbe-491d-c156-7b63b1a834cf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded data**"
      ],
      "metadata": {
        "id": "x6Rf2i58slQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modela5 = RandomForestClassifier()\n",
        "print(\"Model 5 : Random Forest Classifier\", \"\\n\")\n",
        "modela5.fit(X_train2, Y_train2)\n",
        "prediction = modela5.predict(X_val2)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val2, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val2, prediction), \"\\n\")\n",
        "print(classification_report(Y_val2, prediction), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7031da0f-b889-4a7a-8c88-06db4a670901",
        "id": "qOUEhBkDslQH"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 5 : Random Forest Classifier \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurracy of the model : 0.8037109375 \n",
            "\n",
            "Confusion matrix : \n",
            " [[392   3  17   1   0]\n",
            " [  1 103  69   0   0]\n",
            " [ 12  53 320   7   0]\n",
            " [  0   1  33   6   1]\n",
            " [  0   0   1   2   2]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96       413\n",
            "           1       0.64      0.60      0.62       173\n",
            "           2       0.73      0.82      0.77       392\n",
            "           3       0.38      0.15      0.21        41\n",
            "           4       0.67      0.40      0.50         5\n",
            "\n",
            "    accuracy                           0.80      1024\n",
            "   macro avg       0.68      0.58      0.61      1024\n",
            "weighted avg       0.80      0.80      0.80      1024\n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Important features (importance > 2%)**"
      ],
      "metadata": {
        "id": "_uL6mMNHFqf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance = modela5.feature_importances_\n",
        "import matplotlib.pyplot as plt\n",
        "feature_name = np.delete(col_name, [0, 63, 64])\n",
        "removal = []\n",
        "for i in range(62):\n",
        "  if importance[i] < 0.02:\n",
        "    removal.append(i)\n",
        "f_name = np.delete(feature_name, removal)\n",
        "imp = np.delete(importance, removal)\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(f_name,imp, color='b',align='center')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "7f2758bc-18ba-493c-b4a1-9ee0f6150faf",
        "id": "lkKN1OpNslQH"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7Yp5U0oYf4I"
      },
      "source": [
        "# **Gaussian Naive Bayes**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Raw data (after filling NaNs)**"
      ],
      "metadata": {
        "id": "-JmlIZkBtH5L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7556980-d12b-4ab1-8f1f-b5ed609a4644",
        "id": "arm7LZ81tH5R"
      },
      "source": [
        "model6 = GaussianNB()\n",
        "print(\"Model 6 : Gaussian Naive Bayes\", \"\\n\")\n",
        "model6.fit(X_train, Y_train)\n",
        "prediction = model6.predict(X_val)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val, prediction), \"\\n\")\n",
        "print(classification_report(Y_val, prediction), \"\\n\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 6 : Gaussian Naive Bayes \n",
            "\n",
            "Acurracy of the model : 0.529296875 \n",
            "\n",
            "Confusion matrix : \n",
            " [[283  50  66   2  11   1]\n",
            " [  3  95  61   5   9   0]\n",
            " [  9  62 154  50 113   4]\n",
            " [  0   0   2   9  29   1]\n",
            " [  0   0   0   1   1   3]\n",
            " [  0   0   0   0   0   0]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.69      0.80       413\n",
            "           1       0.46      0.55      0.50       173\n",
            "           2       0.54      0.39      0.46       392\n",
            "           3       0.13      0.22      0.17        41\n",
            "           4       0.01      0.20      0.01         5\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.53      1024\n",
            "   macro avg       0.35      0.34      0.32      1024\n",
            "weighted avg       0.68      0.53      0.59      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded data**"
      ],
      "metadata": {
        "id": "Osdrw71rtH5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modela6 = GaussianNB()\n",
        "print(\"Model 6 : Gaussian Naive Bayes\", \"\\n\")\n",
        "modela6.fit(X_train2, Y_train2)\n",
        "prediction = modela6.predict(X_val2)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val2, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val2, prediction), \"\\n\")\n",
        "print(classification_report(Y_val2, prediction), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6812f84e-593f-463d-ef91-35ae99028380",
        "id": "W_j08HDctH5S"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 6 : Gaussian Naive Bayes \n",
            "\n",
            "Acurracy of the model : 0.560546875 \n",
            "\n",
            "Confusion matrix : \n",
            " [[280  55  66   4   8   0]\n",
            " [  3 103  56   7   4   0]\n",
            " [  9  77 178  68  60   0]\n",
            " [  0   0   5  11  24   1]\n",
            " [  0   0   0   1   2   2]\n",
            " [  0   0   0   0   0   0]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.68      0.79       413\n",
            "           1       0.44      0.60      0.50       173\n",
            "           2       0.58      0.45      0.51       392\n",
            "           3       0.12      0.27      0.17        41\n",
            "           4       0.02      0.40      0.04         5\n",
            "           5       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.56      1024\n",
            "   macro avg       0.35      0.40      0.34      1024\n",
            "weighted avg       0.69      0.56      0.61      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgYWNAR_Yf4L"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Raw data (after filling NaNs)**"
      ],
      "metadata": {
        "id": "LVsa6-WUtc86"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd0838a-2eb8-47e9-8cb6-01e390b593c8",
        "id": "XMve06xftc9A"
      },
      "source": [
        "model7 = SVC(gamma='auto')\n",
        "print(\"Model 7 : Support Vector Machine (SVM)\", \"\\n\")\n",
        "model7.fit(X_train, Y_train)\n",
        "prediction = model7.predict(X_val)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val, prediction), \"\\n\")\n",
        "print(classification_report(Y_val, prediction), \"\\n\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 7 : Support Vector Machine (SVM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurracy of the model : 0.77734375 \n",
            "\n",
            "Confusion matrix : \n",
            " [[383   4  26   0   0]\n",
            " [  1  92  80   0   0]\n",
            " [ 13  56 320   3   0]\n",
            " [  0   1  39   1   0]\n",
            " [  0   0   4   1   0]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.95       413\n",
            "           1       0.60      0.53      0.56       173\n",
            "           2       0.68      0.82      0.74       392\n",
            "           3       0.20      0.02      0.04        41\n",
            "           4       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.78      1024\n",
            "   macro avg       0.49      0.46      0.46      1024\n",
            "weighted avg       0.76      0.78      0.76      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded data**"
      ],
      "metadata": {
        "id": "T2EFXuGKtc9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modela7 = SVC(gamma='auto')\n",
        "print(\"Model 7 : Support Vector Machine (SVM)\", \"\\n\")\n",
        "modela7.fit(X_train2, Y_train2)\n",
        "prediction = modela7.predict(X_val2)\n",
        "print(\"Acurracy of the model :\", accuracy_score(Y_val2, prediction), \"\\n\")\n",
        "print(\"Confusion matrix :\",\"\\n\", confusion_matrix(Y_val2, prediction), \"\\n\")\n",
        "print(classification_report(Y_val2, prediction), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "673e338a-bc1a-4d52-e923-d6821afd4658",
        "id": "beNQqJTNtc9B"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 7 : Support Vector Machine (SVM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurracy of the model : 0.3828125 \n",
            "\n",
            "Confusion matrix : \n",
            " [[  0   0 413   0   0]\n",
            " [  0   0 173   0   0]\n",
            " [  0   0 392   0   0]\n",
            " [  0   0  41   0   0]\n",
            " [  0   0   5   0   0]] \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       413\n",
            "           1       0.00      0.00      0.00       173\n",
            "           2       0.38      1.00      0.55       392\n",
            "           3       0.00      0.00      0.00        41\n",
            "           4       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.38      1024\n",
            "   macro avg       0.08      0.20      0.11      1024\n",
            "weighted avg       0.15      0.38      0.21      1024\n",
            " \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble method**"
      ],
      "metadata": {
        "id": "rT-UnxZUCPu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Raw data models**"
      ],
      "metadata": {
        "id": "_piAauRBt82P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "modele = VotingClassifier(estimators=[('LR', model1), ('LDA', model2), ('KNN', model3), ('DT', model4), ('RF', model5), ('GNB', model6), ('SVM', model7)], voting='hard')\n",
        "modele.fit(X_train,Y_train)\n",
        "modele.score(X_val,Y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA-DbFGzCPPw",
        "outputId": "1cc77b14-3755-40db-9926-1428ffbcfac8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.78515625"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded data models**"
      ],
      "metadata": {
        "id": "JXGqrz_Xt_nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "modelee = VotingClassifier(estimators=[('LR', modela1), ('LDA', modela2), ('KNN', modela3), ('DT', modela4), ('RF', modela5), ('GNB', modela6), ('SVM', modela7)], voting='hard')\n",
        "modelee.fit(X_train,Y_train)\n",
        "modelee.score(X_val,Y_val)"
      ],
      "metadata": {
        "id": "WMfhKGXE-e_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8233e3-9e68-4ce3-a611-2a64331b1bd7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7890625"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GHn0_sao-fDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PqEA5hkn-fE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RsNL08lI-fIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lMMQMiig-fKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fqqlSElj-fMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GrtjpeG4-fOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XKcFhIb3-fSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h9-e2k38-fUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yr7syoL_-fXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r9er-Zfk-fYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dV-wpLH2-faX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XEpLsFuE-fcQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
